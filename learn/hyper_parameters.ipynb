{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1be15c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table size: 7043 rows; 22 columns\n",
      "'split' column not found. Creating a random split.\n",
      "Training set size: (5645, 3)\n",
      "Test set size: (1398, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/mle-mlflow/mlflow_venv/lib/python3.10/site-packages/mlflow/models/signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input) if model_input is not None else None\n",
      "Registered model 'churn_model_ivan_panchenko' already exists. Creating a new version of this model...\n",
      "2025/08/11 18:39:54 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: churn_model_ivan_panchenko, version 11\n",
      "Created version '11' of model 'churn_model_ivan_panchenko'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 88fedc3f5a6a462fa182e41cc30ced86\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import mlflow\n",
    "import boto3\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from botocore.exceptions import ClientError\n",
    "import psycopg\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, log_loss\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Constants\n",
    "TABLE_NAME = \"users_churn\"\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "EXPERIMENT_NAME = \"churn_ivan_panchenko\"\n",
    "RUN_NAME = \"feature_selection\"\n",
    "REGISTRY_MODEL_NAME = \"churn_model_ivan_panchenko\"\n",
    "FS_ASSETS = \"fs_assets\"\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def get_env_variable(var_name):\n",
    "    value = os.getenv(var_name)\n",
    "    if not value:\n",
    "        raise ValueError(f\"Environment variable {var_name} is not set in the .env file\")\n",
    "    return value\n",
    "\n",
    "# Get environment variables\n",
    "S3_ENDPOINT_URL = get_env_variable('S3_ENDPOINT_URL')\n",
    "S3_BUCKET_NAME = get_env_variable('S3_BUCKET_NAME')\n",
    "AWS_ACCESS_KEY_ID = get_env_variable('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = get_env_variable('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "# Database connection setup\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv('DB_DESTINATION_HOST'),\n",
    "    \"port\": os.getenv('DB_DESTINATION_PORT'),\n",
    "    \"dbname\": os.getenv('DB_DESTINATION_NAME'),\n",
    "    \"user\": os.getenv('DB_DESTINATION_USER'),\n",
    "    \"password\": os.getenv('DB_DESTINATION_PASSWORD')\n",
    "}\n",
    "assert all([var_value != \"\" for var_value in list(postgres_credentials.values())])\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "# Fetch data from database\n",
    "with psycopg.connect(**connection) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "print(f\"Table size: {df.shape[0]} rows; {df.shape[1]} columns\")\n",
    "\n",
    "# Define features and target\n",
    "features = [\"monthly_charges\", \"total_charges\", \"senior_citizen\"]\n",
    "target = \"target\"\n",
    "test_size = 0.2\n",
    "\n",
    "# Check if 'split' column exists, if not, create a random split\n",
    "if 'split' not in df.columns:\n",
    "    print(\"'split' column not found. Creating a random split.\")\n",
    "    df['split'] = np.random.choice(['train', 'test'], size=len(df), p=[1-test_size, test_size])\n",
    "\n",
    "# Split the data\n",
    "df_train = df[df['split'] == 'train']\n",
    "df_test = df[df['split'] == 'test']\n",
    "\n",
    "X_train = df_train[features]\n",
    "y_train = df_train[target]\n",
    "X_test = df_test[features]\n",
    "y_test = df_test[target]\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# Model parameters\n",
    "loss_function = \"Logloss\"\n",
    "task_type = 'CPU'\n",
    "random_seed = 0\n",
    "iterations = 300\n",
    "verbose = False\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'depth': [4, 6, 8],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'iterations': [iterations],\n",
    "    'loss_function': [loss_function],\n",
    "    'task_type': [task_type],\n",
    "    'random_seed': [random_seed],\n",
    "    'verbose': [verbose]\n",
    "}\n",
    "\n",
    "# Initialize model and perform grid search\n",
    "model = CatBoostClassifier(\n",
    "    loss_function=loss_function,\n",
    "    task_type=task_type,\n",
    "    iterations=iterations,\n",
    "    verbose=verbose,\n",
    "    random_seed=random_seed\n",
    ")\n",
    "\n",
    "cv = GridSearchCV(estimator=model, param_grid=params, cv=2, n_jobs=-1)\n",
    "clf = cv.fit(X_train, y_train)\n",
    "\n",
    "# Set up MLflow\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "# Process results\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "best_params = clf.best_params_\n",
    "\n",
    "model_best = CatBoostClassifier(\n",
    "    # loss_function=loss_function,\n",
    "    # task_type=task_type,\n",
    "    # iterations=iterations,\n",
    "    # verbose=verbose,\n",
    "    # random_seed=random_seed,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "model_best.fit(X_train, y_train)\n",
    "\n",
    "prediction = model_best.predict(X_test)\n",
    "probas = model_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {}\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, prediction).ravel()\n",
    "_, err1, _, err2 = confusion_matrix(y_test, prediction, normalize='all').ravel()\n",
    "auc = roc_auc_score(y_test, probas)\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "logloss = log_loss(y_test, prediction)\n",
    "\n",
    "metrics.update({\n",
    "    \"err1\": err1, \"err2\": err2, \"auc\": auc, \"precision\": precision,\n",
    "    \"recall\": recall, \"f1\": f1, \"logloss\": logloss,\n",
    "    \"mean_fit_time\": cv_results['mean_fit_time'].mean(),\n",
    "    \"std_fit_time\": cv_results['std_fit_time'].mean(),\n",
    "    \"mean_test_score\": cv_results['mean_test_score'].mean(),\n",
    "    \"std_test_score\": cv_results['std_test_score'].mean(),\n",
    "    \"best_score\": clf.best_score_\n",
    "})\n",
    "\n",
    "# Log model with MLflow\n",
    "pip_requirements = '../requirements.txt'\n",
    "signature = mlflow.models.infer_signature(X_test, prediction)\n",
    "input_example = X_test[:10]\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    model_info = mlflow.catboost.log_model(\n",
    "        cb_model=model_best,\n",
    "        artifact_path=\"models\",\n",
    "        registered_model_name=REGISTRY_MODEL_NAME,\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        pip_requirements=pip_requirements\n",
    "    )\n",
    "    cv_info = mlflow.sklearn.log_model(cv, artifact_path='cv')\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "print(f\"Run ID: {run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120fe06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (5634, 3)\n",
      "Test set size: (1409, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/mle-mlflow/mlflow_venv/lib/python3.10/site-packages/mlflow/models/signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input) if model_input is not None else None\n",
      "Registered model 'churn_model_ivan_panchenko' already exists. Creating a new version of this model...\n",
      "2025/08/11 18:46:20 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: churn_model_ivan_panchenko, version 12\n",
      "Created version '12' of model 'churn_model_ivan_panchenko'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: bd29c3f29adb47bfb89af5fb03602fc5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import psycopg\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, log_loss\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Constants\n",
    "TABLE_NAME = \"users_churn\"\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "EXPERIMENT_NAME = \"churn_ivan_panchenko\"\n",
    "RUN_NAME = \"feature_selection\"\n",
    "REGISTRY_MODEL_NAME = \"churn_model_ivan_panchenko\"\n",
    "FS_ASSETS = \"fs_assets\"\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Database connection and data fetching (unchanged)\n",
    "# ...\n",
    "\n",
    "# Define features and target\n",
    "features = [\"monthly_charges\", \"total_charges\", \"senior_citizen\"]\n",
    "target = \"target\"\n",
    "split_column = \"split\"\n",
    "stratify_column = \"target\"\n",
    "test_size = 0.2\n",
    "\n",
    "df = df.sort_values(by=[split_column])\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=test_size, shuffle=False)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# Model parameters\n",
    "loss_function = \"Logloss\"\n",
    "task_type = 'CPU'\n",
    "random_seed = 0\n",
    "iterations = 300\n",
    "verbose = False\n",
    "\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'depth': [4, 6, 8],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'iterations': [iterations],\n",
    "    'loss_function': [loss_function],\n",
    "    'task_type': [task_type],\n",
    "    'random_seed': [random_seed],\n",
    "    'verbose': [verbose]\n",
    "}\n",
    "\n",
    "# Initialize model and perform random search\n",
    "model = CatBoostClassifier(\n",
    "    loss_function=loss_function,\n",
    "    task_type=task_type,\n",
    "    iterations=iterations,\n",
    "    verbose=verbose,\n",
    "    random_seed=random_seed\n",
    ")\n",
    "\n",
    "cv = RandomizedSearchCV(estimator=model, param_distributions=param_distributions, n_iter=20, cv=2, n_jobs=-1, random_state=random_seed)\n",
    "clf = cv.fit(X_train, y_train)\n",
    "\n",
    "# Process results\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "best_params = clf.best_params_\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    # loss_function=loss_function,\n",
    "    # task_type=task_type,\n",
    "    # iterations=iterations,\n",
    "    # verbose=verbose,\n",
    "    # random_seed=random_seed,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "probas = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {}\n",
    "_, err1, _, err2 = confusion_matrix(y_test, prediction, normalize='all').ravel()\n",
    "auc = roc_auc_score(y_test, probas)\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "logloss = log_loss(y_test, prediction)\n",
    "\n",
    "metrics.update({\n",
    "    \"err1\": err1, \"err2\": err2, \"auc\": auc, \"precision\": precision,\n",
    "    \"recall\": recall, \"f1\": f1, \"logloss\": logloss,\n",
    "    \"mean_fit_time\": cv_results['mean_fit_time'].mean(),\n",
    "    \"std_fit_time\": cv_results['std_fit_time'].mean(),\n",
    "    \"mean_test_score\": cv_results['mean_test_score'].mean(),\n",
    "    \"std_test_score\": cv_results['std_test_score'].mean(),\n",
    "    \"best_score\": clf.best_score_\n",
    "})\n",
    "\n",
    "# Log model with MLflow\n",
    "pip_requirements = '../requirements.txt'\n",
    "signature = mlflow.models.infer_signature(X_test, prediction)\n",
    "input_example = X_test[:10]\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    model_info = mlflow.catboost.log_model(\n",
    "        cb_model=model,\n",
    "        artifact_path=\"models\",\n",
    "        registered_model_name=REGISTRY_MODEL_NAME,\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        pip_requirements=pip_requirements\n",
    "    )\n",
    "    cv_info = mlflow.sklearn.log_model(cv, artifact_path='cv')\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "print(f\"Run ID: {run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9cc09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
